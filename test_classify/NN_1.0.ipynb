{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import random\n",
    "from tensorflow.keras import Model, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"test_classification_data_with_date.csv\", index_col = False)\n",
    "df = pd.read_csv(\"test_classification_data.csv\", index_col = False)\n",
    "# df = df.drop(df[(df.Class == 'H')].index).drop('date', axis = 1)\n",
    "df = df.drop('date', axis = 1)\n",
    "X = df.drop('Class', axis = 1)\n",
    "Y = df['Class']\n",
    "\n",
    "kf = KFold(n_splits = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "\n",
    "# dataset parameters\n",
    "num_classes = 2\n",
    "num_features = 50\n",
    "\n",
    "# Training parameters\n",
    "learning_rate = 0.01\n",
    "training_steps = 2000\n",
    "batch_size = 256\n",
    "display_steps = 250\n",
    "\n",
    "# Network parameters\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 128\n",
    "\n",
    "# Create NN model\n",
    "class Neural_Network(Model):\n",
    "    # Set layers\n",
    "    def __init__(self):\n",
    "        tf.keras.backend.clear_session()\n",
    "        super(Neural_Network, self).__init__();\n",
    "        # 1st fully connected hidden layer\n",
    "        self.fc1 = layers.Dense(n_hidden_1, activation = tf.nn.relu)\n",
    "        # 2nd fully connected hidden layer\n",
    "        self.fc2 = layers.Dense(n_hidden_2, activation = tf.nn.relu)\n",
    "        # Output layer\n",
    "        self.out = layers.Dense(num_classes)\n",
    "        \n",
    "    # Set forward pass\n",
    "    def call(self, x, is_training = False):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        if not is_training:\n",
    "            # tf cross entropy expect logits without softmax, so only\n",
    "            # apply softmax when not training.\n",
    "            x = tf.nn.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Cross-Entropy loss function.\n",
    "def cross_entropy_NN(y_pred, y_true):\n",
    "    # Convert labels to int64 for tf cross-entropy function\n",
    "    y_true = tf.cast(y_true, tf.int64)\n",
    "    # Apply softmax to logits and compute cross-entropy\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y_true, logits = y_pred)\n",
    "    # Average loss across batch\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# Accuracy metric.\n",
    "def accuracy_NN(y_pred, y_true):\n",
    "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis = -1)\n",
    "\n",
    "# Optimization process\n",
    "def run_optimization_NN(x, y):\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = neural_network(x, is_training = True)\n",
    "        loss = cross_entropy_NN(pred, y)\n",
    "        \n",
    "    trainable_variables = neural_network.trainable_variables\n",
    "    \n",
    "    gradients = g.gradient(loss, trainable_variables)\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 5, loss: 1.049319, accuracy: 0.535156\n",
      "step: 250, loss: 0.079084, accuracy: 1.000000\n",
      "step: 500, loss: 0.025989, accuracy: 1.000000\n",
      "step: 750, loss: 0.016170, accuracy: 1.000000\n",
      "step: 1000, loss: 0.010561, accuracy: 1.000000\n",
      "step: 1250, loss: 0.008032, accuracy: 1.000000\n",
      "step: 1500, loss: 0.004552, accuracy: 1.000000\n",
      "step: 1750, loss: 0.004752, accuracy: 1.000000\n",
      "step: 2000, loss: 0.003483, accuracy: 1.000000\n",
      "Test Accuracy: 0.769231\n",
      "step: 5, loss: 3.246548, accuracy: 0.433594\n",
      "step: 250, loss: 0.007425, accuracy: 1.000000\n",
      "step: 500, loss: 0.004235, accuracy: 1.000000\n",
      "step: 750, loss: 0.003088, accuracy: 1.000000\n",
      "step: 1000, loss: 0.002291, accuracy: 1.000000\n",
      "step: 1250, loss: 0.001644, accuracy: 1.000000\n",
      "step: 1500, loss: 0.001691, accuracy: 1.000000\n",
      "step: 1750, loss: 0.001419, accuracy: 1.000000\n",
      "step: 2000, loss: 0.001269, accuracy: 1.000000\n",
      "Test Accuracy: 0.615385\n",
      "step: 5, loss: 1.590968, accuracy: 0.644531\n",
      "step: 250, loss: 0.012302, accuracy: 1.000000\n",
      "step: 500, loss: 0.007025, accuracy: 1.000000\n",
      "step: 750, loss: 0.004670, accuracy: 1.000000\n",
      "step: 1000, loss: 0.003442, accuracy: 1.000000\n",
      "step: 1250, loss: 0.002953, accuracy: 1.000000\n",
      "step: 1500, loss: 0.002245, accuracy: 1.000000\n",
      "step: 1750, loss: 0.001979, accuracy: 1.000000\n",
      "step: 2000, loss: 0.001706, accuracy: 1.000000\n",
      "Test Accuracy: 1.000000\n",
      "INFO:tensorflow:Assets written to: test_NN_1.0\\assets\n"
     ]
    }
   ],
   "source": [
    "# Build NN model\n",
    "neural_network = Neural_Network()\n",
    "\n",
    "# Stochastic gradient descent optimizer.\n",
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "    x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "#     x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n",
    "#     x_train, x_test = x_train/255, x_test/255\n",
    "\n",
    "    # Use tf.data API to shuffle and batch data.\n",
    "    train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_data = train_data.repeat().shuffle(20000).batch(batch_size).prefetch(1)\n",
    "    for step, (batch_x, batch_y) in enumerate (train_data.take(training_steps), 1):\n",
    "        run_optimization_NN(batch_x, batch_y)\n",
    "\n",
    "        if step % display_steps == 0 or step == 5:\n",
    "            pred = neural_network(batch_x, is_training = True)\n",
    "            loss = cross_entropy_NN(pred, batch_y)\n",
    "            acc = accuracy_NN(pred, batch_y)\n",
    "            print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))\n",
    "        \n",
    "    # Test model on validation set.\n",
    "    pred = neural_network(x_test, is_training = False)\n",
    "    print(\"Test Accuracy: %f\" % accuracy_NN(pred, y_test))\n",
    "\n",
    "neural_network.save('test_NN_1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.85714287, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1.0000000e+00 4.0674752e-08]\n",
      " [9.9966788e-01 3.3207354e-04]\n",
      " [1.0000000e+00 2.8410946e-15]\n",
      " [1.0000000e+00 7.2440810e-11]\n",
      " [1.0000000e+00 1.7098918e-08]\n",
      " [9.9999988e-01 9.1995268e-08]\n",
      " [9.9999726e-01 2.7054641e-06]\n",
      " [9.9999857e-01 1.4125483e-06]\n",
      " [9.9934870e-01 6.5131544e-04]\n",
      " [7.2548020e-04 9.9927455e-01]\n",
      " [2.7224720e-01 7.2775280e-01]\n",
      " [5.0495164e-03 9.9495053e-01]\n",
      " [1.0000000e+00 8.2555345e-11]\n",
      " [1.0000000e+00 2.4224992e-08]], shape=(14, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = np.array(X, np.float32)\n",
    "pred = neural_network(x, is_training = False)\n",
    "print(accuracy_NN(pred, Y))\n",
    "\n",
    "T = pd.read_csv(\"test_data.csv\", index_col = False)\n",
    "T = T.drop('Date', axis = 1)\n",
    "x_t = T.drop('Class', axis = 1)\n",
    "x_t = np.array(x_t, np.float32)\n",
    "y_t = T['Class']\n",
    "pred = neural_network(x_t, is_training = False)\n",
    "print(accuracy_NN(pred, y_t))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"neural__network\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  13056     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  258       \n",
      "=================================================================\n",
      "Total params: 46,210\n",
      "Trainable params: 46,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[<tf.Variable 'neural__network/dense/kernel:0' shape=(50, 256) dtype=float32, numpy=\n",
      "array([[-0.04386537, -0.13827033, -0.09660842, ..., -0.0846169 ,\n",
      "        -0.012336  , -0.02081989],\n",
      "       [-0.05211613, -0.12310857, -0.04572839, ...,  0.02974619,\n",
      "         0.03060456,  0.09097918],\n",
      "       [-0.01048291, -0.12628607, -0.10894922, ...,  0.02029113,\n",
      "         0.046785  , -0.04976653],\n",
      "       ...,\n",
      "       [ 0.08726799,  0.13501416, -0.07717171, ..., -0.12443569,\n",
      "        -0.08914192, -0.1160024 ],\n",
      "       [-0.00471932, -0.04718503, -0.07861742, ...,  0.07425724,\n",
      "        -0.08491936, -0.08907231],\n",
      "       [-0.02199547, -0.1394775 ,  0.08241737, ...,  0.05181617,\n",
      "         0.04338351, -0.06298225]], dtype=float32)>, <tf.Variable 'neural__network/dense/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([ 1.23828606e-04, -1.49020832e-03,  0.00000000e+00,  3.45534179e-04,\n",
      "        1.43996824e-03, -5.06521785e-04, -1.53451518e-03, -2.35517859e-04,\n",
      "        5.32127859e-04,  1.36969064e-03, -9.69715693e-05, -1.21267908e-03,\n",
      "        6.08249102e-05, -1.45551877e-03, -1.21752615e-03, -2.69375567e-04,\n",
      "       -1.62568421e-03, -1.25990238e-03, -2.42433930e-03, -7.13259142e-05,\n",
      "        1.77880400e-03,  1.34386448e-03,  1.05425087e-03, -1.05952309e-03,\n",
      "        4.91088070e-03, -7.26585867e-08, -1.28890143e-03,  2.01425166e-03,\n",
      "        8.19539942e-04, -1.69206725e-03, -3.58017860e-04,  0.00000000e+00,\n",
      "        2.45848059e-04,  4.51922155e-04, -5.43872666e-05,  6.86672633e-04,\n",
      "        8.85118556e-04, -7.11610264e-05, -3.99783114e-03,  1.62366428e-03,\n",
      "        8.61023262e-04,  2.42383292e-04, -6.63799117e-04, -2.31806218e-04,\n",
      "        1.06327515e-03,  3.68824182e-03, -6.76591531e-04,  0.00000000e+00,\n",
      "        0.00000000e+00,  1.70524436e-04,  1.19066171e-04, -1.89409161e-03,\n",
      "       -1.69211405e-03,  0.00000000e+00, -1.01313542e-03,  7.65733712e-04,\n",
      "        0.00000000e+00,  0.00000000e+00, -1.07045635e-03,  0.00000000e+00,\n",
      "        3.61750717e-03,  3.26652807e-04, -1.46621070e-03,  0.00000000e+00,\n",
      "       -2.43220129e-03,  1.27029151e-03, -1.58866763e-03,  0.00000000e+00,\n",
      "        0.00000000e+00, -1.06462615e-03,  2.74510867e-08,  3.22113076e-04,\n",
      "       -3.21841729e-03, -7.03974627e-04,  1.00751279e-03,  5.78488107e-04,\n",
      "       -9.09272872e-04,  8.39438522e-04, -2.61225109e-03,  0.00000000e+00,\n",
      "       -2.30527439e-04,  0.00000000e+00,  7.17201270e-04, -3.44583008e-04,\n",
      "        0.00000000e+00, -1.54501860e-04, -1.16053538e-03,  3.28372902e-04,\n",
      "        6.86180545e-04, -8.61611508e-04, -2.90932134e-03, -5.57356339e-04,\n",
      "        1.90602243e-03,  9.22852021e-04,  8.78168503e-04, -4.64267010e-04,\n",
      "        1.34915800e-03,  2.33264896e-03,  0.00000000e+00, -5.49073447e-04,\n",
      "       -1.99785463e-05, -2.65255244e-03, -1.17023708e-03,  3.51772597e-03,\n",
      "        1.90057396e-03,  4.18050360e-04,  6.43825799e-04, -5.51454374e-04,\n",
      "        6.34013792e-04, -2.49522924e-03, -1.05909735e-03,  4.17430303e-04,\n",
      "       -5.86181413e-04,  1.56908226e-03,  1.22047577e-03,  3.34749493e-04,\n",
      "       -9.89682623e-04, -1.40675623e-03,  5.56545856e-04,  0.00000000e+00,\n",
      "       -7.05164784e-05,  1.47558202e-03,  7.43430224e-04,  1.81301474e-03,\n",
      "        0.00000000e+00, -1.33752974e-03, -1.30437096e-04,  1.94836157e-05,\n",
      "        4.93786531e-04, -3.15659819e-03,  0.00000000e+00,  1.06916668e-04,\n",
      "        0.00000000e+00,  1.69519032e-03, -7.41186086e-04, -1.64903281e-03,\n",
      "        1.86891330e-03,  0.00000000e+00,  2.01356670e-04, -2.68343254e-04,\n",
      "        3.99036100e-04,  1.58064684e-03, -2.27042532e-04,  1.16400933e-03,\n",
      "       -1.99883449e-04, -7.81135532e-05, -2.61153467e-03,  5.94079495e-07,\n",
      "        1.20117771e-03, -1.54214981e-03, -8.27760203e-04,  1.50573242e-03,\n",
      "        6.84328203e-04,  3.70632741e-04,  3.65576008e-03, -3.97913682e-04,\n",
      "       -2.19878764e-03,  8.25909607e-04,  2.41193295e-04,  7.33007444e-04,\n",
      "       -2.25688884e-04, -5.68546995e-04,  0.00000000e+00,  3.47750192e-03,\n",
      "        0.00000000e+00,  0.00000000e+00, -2.80703331e-04, -2.41069682e-03,\n",
      "        3.85042542e-04,  0.00000000e+00,  2.84306647e-04, -2.93692952e-04,\n",
      "        0.00000000e+00, -5.34189818e-03,  6.23401138e-05,  2.91349576e-03,\n",
      "        2.29491616e-05, -1.05111662e-03,  4.36390168e-04, -1.78625472e-04,\n",
      "       -2.74743914e-04,  2.52615544e-03, -1.67495781e-03, -5.84356894e-04,\n",
      "       -1.05402619e-03,  7.39278446e-04,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  7.67316611e-04, -4.57050104e-04,  8.94034165e-04,\n",
      "        2.88756593e-04, -1.06981618e-03, -3.82396422e-04,  1.97144202e-03,\n",
      "       -3.56620993e-04,  3.05037363e-04,  2.78471154e-03,  4.07836196e-04,\n",
      "        0.00000000e+00, -3.73348536e-04, -6.29739021e-04, -1.90006453e-03,\n",
      "       -2.80103995e-03, -5.23923663e-04,  1.33952301e-03,  0.00000000e+00,\n",
      "       -1.26526691e-03,  2.10584607e-03, -3.36415629e-04,  3.28395952e-04,\n",
      "        6.33454358e-04, -1.80800050e-03, -2.77450704e-03, -2.52192491e-03,\n",
      "       -7.09242231e-05, -2.01917789e-03,  0.00000000e+00, -6.25859422e-04,\n",
      "        6.71494752e-04,  0.00000000e+00, -6.48475107e-05,  0.00000000e+00,\n",
      "       -3.38937156e-04, -4.25732742e-06, -1.14658766e-03, -4.52670502e-04,\n",
      "        6.29769755e-04,  2.61298241e-03, -3.19277402e-04,  0.00000000e+00,\n",
      "        5.77039260e-04,  1.77037087e-04,  1.15323710e-04, -1.35414957e-04,\n",
      "       -4.66288853e-04, -1.17337913e-03, -2.93135317e-03, -2.30577984e-03,\n",
      "        3.27859510e-04,  1.18629937e-03,  2.53660837e-04, -2.80740368e-03,\n",
      "       -6.87520253e-04,  1.10956503e-03,  0.00000000e+00, -4.66963602e-03,\n",
      "        1.01513695e-04,  5.47889620e-04, -1.03449682e-03, -1.30045402e-03,\n",
      "       -1.84446003e-03,  0.00000000e+00, -8.76087928e-04, -4.37472714e-04],\n",
      "      dtype=float32)>, <tf.Variable 'neural__network/dense_1/kernel:0' shape=(256, 128) dtype=float32, numpy=\n",
      "array([[ 0.11237496,  0.00239561, -0.11138255, ...,  0.08165963,\n",
      "        -0.05574093,  0.00705934],\n",
      "       [ 0.0811566 , -0.04161435, -0.01162599, ...,  0.08844467,\n",
      "        -0.12436613,  0.06150564],\n",
      "       [ 0.00632149,  0.0845437 , -0.05186641, ..., -0.08895808,\n",
      "        -0.06554583,  0.11308593],\n",
      "       ...,\n",
      "       [-0.00157213, -0.09755889,  0.06218034, ...,  0.09491327,\n",
      "        -0.07712162, -0.12277281],\n",
      "       [-0.0057407 , -0.02322003,  0.09020931, ...,  0.02842476,\n",
      "         0.0845267 , -0.04775833],\n",
      "       [-0.03571706,  0.09422432,  0.11273975, ..., -0.05097556,\n",
      "         0.07752264, -0.03875116]], dtype=float32)>, <tf.Variable 'neural__network/dense_1/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 1.00177662e-04, -1.18563091e-03, -1.17177214e-03, -7.06661551e-04,\n",
      "        5.17621302e-05,  1.21578923e-03,  0.00000000e+00, -5.45924471e-04,\n",
      "        8.06373020e-04,  5.98408922e-04, -3.41619976e-04,  3.26840719e-03,\n",
      "        4.98520749e-05, -8.47007497e-04, -3.38893617e-04, -2.53806985e-03,\n",
      "        1.56936239e-05, -3.03837587e-03, -1.53444812e-03, -3.40553117e-04,\n",
      "       -3.32614640e-03,  9.42088722e-04, -1.14657206e-03, -4.97728935e-04,\n",
      "       -5.91684598e-04,  1.68100791e-03,  2.23557837e-03,  9.74865805e-04,\n",
      "        8.20464280e-04, -1.31526031e-03, -1.31855614e-03, -6.02939050e-04,\n",
      "       -1.43529696e-03,  2.13143998e-03,  1.56077719e-03,  1.05212757e-03,\n",
      "       -6.10336661e-04,  1.28702086e-03, -2.96982384e-04,  4.80833405e-04,\n",
      "       -4.09740227e-04, -1.56695046e-03, -7.83340132e-04, -1.03763992e-03,\n",
      "       -1.74639514e-03, -1.53732044e-03,  2.90350290e-04, -4.86403354e-04,\n",
      "        2.87757674e-03, -5.20608091e-06, -6.92098227e-04, -1.54646242e-03,\n",
      "        4.48491052e-03,  1.45129479e-06,  4.17145842e-04,  6.81363046e-04,\n",
      "        1.41674047e-03,  1.44616512e-04, -2.26603152e-04, -2.62984890e-04,\n",
      "        5.43400587e-04,  0.00000000e+00, -7.42944307e-04, -1.00700988e-03,\n",
      "        1.67918066e-03, -1.76111958e-03, -3.28552531e-04, -2.88741663e-03,\n",
      "        1.04489945e-05, -6.34451024e-31, -2.84448825e-03,  8.24162329e-04,\n",
      "        3.67618166e-04, -3.94463399e-03,  8.43174348e-04, -2.67128809e-04,\n",
      "       -8.19998793e-04,  1.44633534e-03,  1.47630495e-03, -2.74786435e-04,\n",
      "        8.65835987e-04,  0.00000000e+00, -2.37076590e-03,  1.56609528e-03,\n",
      "       -5.40126173e-04, -2.96138483e-03, -9.90240020e-04, -1.88922649e-03,\n",
      "        1.50926237e-03, -1.31287379e-04,  1.18772511e-03, -2.10111635e-03,\n",
      "       -5.16413784e-05, -1.20807577e-04, -1.05812075e-03,  3.42969364e-03,\n",
      "       -6.72202033e-04, -6.97390409e-04, -2.43338128e-03,  0.00000000e+00,\n",
      "        5.89404255e-04, -1.26673709e-04, -7.62878975e-04, -7.49872823e-04,\n",
      "       -1.26279588e-03, -3.25660891e-04, -1.77445880e-03,  9.96498391e-04,\n",
      "        0.00000000e+00, -3.80240701e-04, -1.19141175e-03, -1.78101909e-04,\n",
      "        4.47158422e-03,  1.37589441e-03,  2.97783106e-03,  2.14174856e-03,\n",
      "       -5.33850689e-04, -9.62173799e-04,  1.28508196e-03, -1.06435583e-03,\n",
      "        0.00000000e+00, -5.94172277e-04,  2.70613306e-03,  0.00000000e+00,\n",
      "       -7.12482957e-04, -6.11041149e-04,  1.73906714e-03, -1.33784977e-03],\n",
      "      dtype=float32)>, <tf.Variable 'neural__network/dense_2/kernel:0' shape=(128, 2) dtype=float32, numpy=\n",
      "array([[ 0.17241949,  0.00762671],\n",
      "       [ 0.1176525 , -0.23692521],\n",
      "       [ 0.20971619, -0.06458331],\n",
      "       [-0.04521221, -0.01139842],\n",
      "       [ 0.03572074, -0.26129895],\n",
      "       [ 0.28975752, -0.10218774],\n",
      "       [-0.19475801,  0.09706046],\n",
      "       [-0.05821966, -0.19477944],\n",
      "       [ 0.01326081, -0.23318607],\n",
      "       [-0.03495495,  0.40906242],\n",
      "       [-0.04968817, -0.2098034 ],\n",
      "       [ 0.30539376, -0.25798866],\n",
      "       [ 0.01746574,  0.01259471],\n",
      "       [-0.09796339,  0.13825266],\n",
      "       [-0.09316203, -0.07651571],\n",
      "       [ 0.00352964, -0.18779892],\n",
      "       [-0.00653496, -0.07786856],\n",
      "       [-0.2718901 ,  0.22586775],\n",
      "       [ 0.22571592, -0.16000019],\n",
      "       [ 0.08966283, -0.0905678 ],\n",
      "       [-0.02548383,  0.22095314],\n",
      "       [ 0.05661703, -0.21696112],\n",
      "       [ 0.05569004,  0.17598362],\n",
      "       [-0.05958394,  0.00951019],\n",
      "       [-0.02108023, -0.14170706],\n",
      "       [ 0.09659243, -0.24686152],\n",
      "       [ 0.2526244 , -0.06879244],\n",
      "       [ 0.21487886, -0.01096328],\n",
      "       [-0.06205214,  0.08540285],\n",
      "       [ 0.02608534, -0.0713563 ],\n",
      "       [-0.09548569,  0.1110946 ],\n",
      "       [-0.05624182,  0.16514409],\n",
      "       [ 0.09703642, -0.16035295],\n",
      "       [-0.06182595,  0.18679062],\n",
      "       [ 0.02659462, -0.15605615],\n",
      "       [ 0.08145757,  0.16802628],\n",
      "       [ 0.03462571,  0.12131004],\n",
      "       [ 0.06812199, -0.1837354 ],\n",
      "       [-0.14039035, -0.1736221 ],\n",
      "       [-0.08884882,  0.10928113],\n",
      "       [-0.0203367 ,  0.01973007],\n",
      "       [ 0.08863216, -0.17717762],\n",
      "       [ 0.31970406, -0.19250737],\n",
      "       [-0.28581813,  0.25084513],\n",
      "       [ 0.13460614,  0.15524018],\n",
      "       [-0.16418102,  0.10557406],\n",
      "       [ 0.14281932,  0.05543433],\n",
      "       [ 0.13697991, -0.1016195 ],\n",
      "       [ 0.05295222, -0.21403347],\n",
      "       [-0.05213031, -0.04996213],\n",
      "       [-0.10573284, -0.0095355 ],\n",
      "       [-0.21916673,  0.05183741],\n",
      "       [ 0.30691695, -0.10987715],\n",
      "       [ 0.13215731,  0.05786132],\n",
      "       [-0.16436078, -0.00615338],\n",
      "       [-0.1283134 ,  0.06777645],\n",
      "       [-0.20794785,  0.24311097],\n",
      "       [-0.09745332,  0.11111823],\n",
      "       [ 0.204649  ,  0.18162322],\n",
      "       [-0.02831895, -0.13815491],\n",
      "       [ 0.24616587, -0.04235286],\n",
      "       [-0.20090704, -0.00657682],\n",
      "       [-0.23595595,  0.03180706],\n",
      "       [ 0.03667032,  0.15243475],\n",
      "       [ 0.1206816 , -0.12664467],\n",
      "       [ 0.29393157, -0.0415693 ],\n",
      "       [ 0.01014287, -0.03888714],\n",
      "       [ 0.208298  ,  0.00767711],\n",
      "       [-0.06604563,  0.01845566],\n",
      "       [-0.0631398 ,  0.13230143],\n",
      "       [-0.30473077,  0.3246823 ],\n",
      "       [ 0.1088194 ,  0.2619197 ],\n",
      "       [ 0.14145423, -0.08191756],\n",
      "       [-0.4105352 ,  0.39737734],\n",
      "       [-0.13387766,  0.2205951 ],\n",
      "       [ 0.02454979,  0.05965853],\n",
      "       [ 0.2277535 ,  0.00899315],\n",
      "       [ 0.16554591, -0.183513  ],\n",
      "       [ 0.25590062, -0.06623296],\n",
      "       [-0.17543462, -0.08614763],\n",
      "       [-0.06178039,  0.1211143 ],\n",
      "       [ 0.06868275, -0.14539894],\n",
      "       [-0.2148872 ,  0.22811131],\n",
      "       [-0.08388471,  0.12761135],\n",
      "       [-0.07704158, -0.20635715],\n",
      "       [-0.3419206 ,  0.24694477],\n",
      "       [-0.19009514,  0.27540752],\n",
      "       [ 0.21707492, -0.10698476],\n",
      "       [-0.24412219, -0.1158844 ],\n",
      "       [ 0.00798034, -0.0056312 ],\n",
      "       [-0.07289974, -0.17065337],\n",
      "       [-0.09252387,  0.15223968],\n",
      "       [ 0.26571786, -0.26910514],\n",
      "       [ 0.21037096, -0.05458865],\n",
      "       [-0.17002633,  0.09692439],\n",
      "       [ 0.31573167, -0.25613627],\n",
      "       [-0.07862002, -0.21822524],\n",
      "       [ 0.1050327 ,  0.27342   ],\n",
      "       [-0.29875442,  0.25500113],\n",
      "       [-0.20759532,  0.04389019],\n",
      "       [ 0.04638832,  0.12297259],\n",
      "       [ 0.03120946, -0.09297556],\n",
      "       [ 0.09681268, -0.13920324],\n",
      "       [-0.2321893 ,  0.13571925],\n",
      "       [-0.31858695,  0.27613863],\n",
      "       [ 0.11752111,  0.20161906],\n",
      "       [ 0.22857463, -0.07228369],\n",
      "       [ 0.16231512, -0.21166365],\n",
      "       [-0.07640515,  0.17416735],\n",
      "       [ 0.05289656, -0.1625407 ],\n",
      "       [ 0.19289848, -0.1251675 ],\n",
      "       [ 0.2018478 ,  0.12707122],\n",
      "       [ 0.22114114, -0.33052814],\n",
      "       [ 0.15293077,  0.02491407],\n",
      "       [ 0.01487448, -0.28070444],\n",
      "       [ 0.08948082, -0.22823383],\n",
      "       [ 0.09203046,  0.03011349],\n",
      "       [ 0.39338028, -0.30823115],\n",
      "       [ 0.14098161, -0.16383104],\n",
      "       [ 0.1476937 , -0.26295745],\n",
      "       [-0.10298655, -0.08296558],\n",
      "       [ 0.09975652,  0.16708201],\n",
      "       [ 0.21747686, -0.0899039 ],\n",
      "       [ 0.02714683, -0.12232783],\n",
      "       [-0.02551387, -0.14552158],\n",
      "       [ 0.17524453, -0.02352705],\n",
      "       [-0.10691188,  0.18591718],\n",
      "       [ 0.00596732,  0.11743078]], dtype=float32)>, <tf.Variable 'neural__network/dense_2/bias:0' shape=(2,) dtype=float32, numpy=array([ 0.00160088, -0.00160086], dtype=float32)>]\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '23/3/2021'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9c451d14a8ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_data.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mx_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Class'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mx_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0my_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Documents\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1781\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1783\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Documents\\Anaconda\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '23/3/2021'"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('test_NN_1.0')\n",
    "new_model.summary()\n",
    "print(new_model.trainable_variables)\n",
    "\n",
    "x = np.array(X, np.float32)\n",
    "pred = new_model(x, is_training = False)\n",
    "print(accuracy_NN(pred, Y))\n",
    "T = pd.read_csv(\"test_data.csv\", index_col = False)\n",
    "x_t = T.drop('Class', axis = 1)\n",
    "x_t = np.array(x_t, np.float32)\n",
    "y_t = T['Class']\n",
    "pred = new_model(x_t, is_training = False)\n",
    "print(accuracy_NN(pred, y_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_weight = np.asarray(neural_network.trainable_variables[0])\n",
    "dense_bias = np.asarray(neural_network.trainable_variables[1])\n",
    "dense1_weight = np.asarray(neural_network.trainable_variables[2])\n",
    "dense1_bias = np.asarray(neural_network.trainable_variables[3])\n",
    "dense2_weight = np.asarray(neural_network.trainable_variables[4])\n",
    "dense2_bias = np.asarray(neural_network.trainable_variables[5])\n",
    "# np.savetxt('trainable_variables/dense_weight_50x256.csv', np.transpose(dense_weight), delimiter=',')\n",
    "# np.savetxt('trainable_variables/dense_bias_256.csv', np.transpose(dense_bias), delimiter=',')\n",
    "# np.savetxt('trainable_variables/dense1_weight_256x128.csv', np.transpose(dense1_weight), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_weight = np.asarray(neural_network.trainable_variables[0])\n",
    "dense_bias = np.asarray(neural_network.trainable_variables[1])\n",
    "dense1_weight = np.asarray(neural_network.trainable_variables[2])\n",
    "dense1_bias = np.asarray(neural_network.trainable_variables[3])\n",
    "dense2_weight = np.asarray(neural_network.trainable_variables[4])\n",
    "dense2_bias = np.asarray(neural_network.trainable_variables[5])\n",
    "# np.savetxt('trainable_variables/dense_weight_50x256.csv', np.transpose(dense_weight), delimiter=',')\n",
    "# np.savetxt('trainable_variables/dense_bias_256.csv', np.transpose(dense_bias), delimiter=',')\n",
    "# np.savetxt('trainable_variables/dense1_weight_256x128.csv', np.transpose(dense1_weight), delimiter=',')\n",
    "# np.savetxt('trainable_variables/dense1_bias_128.csv', np.transpose(dense1_bias), delimiter=',')\n",
    "# np.savetxt('trainable_variables/dense2_weight_128x2.csv', np.transpose(dense2_weight), delimiter=',')\n",
    "# np.savetxt('trainable_variables/dense2_bias_2.csv', np.transpose(dense2_bias), delimiter=',')\n",
    "np.savetxt('trainable_variables/dense_weight_50x256.csv', dense_weight, delimiter=',')\n",
    "np.savetxt('trainable_variables/dense_bias_256.csv', dense_bias, delimiter=',')\n",
    "np.savetxt('trainable_variables/dense1_weight_256x128.csv', dense1_weight, delimiter=',')\n",
    "np.savetxt('trainable_variables/dense1_bias_128.csv', dense1_bias, delimiter=',')\n",
    "np.savetxt('trainable_variables/dense2_weight_128x2.csv', dense2_weight, delimiter=',')\n",
    "np.savetxt('trainable_variables/dense2_bias_2.csv', dense2_bias, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
