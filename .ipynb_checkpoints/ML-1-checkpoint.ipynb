{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import Model, layers\n",
    "\n",
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns = ['image', 'cells'])\n",
    "\n",
    "# # base_dir = os.path.join(os.path.abspath(''), \"Aria1/\")\n",
    "# base_dir = \"../../20201020134002/Aria1/\"\n",
    "# img_prefix = \"Area1_Cell_\"\n",
    "# img_suffix = \"_bin.png\"\n",
    "\n",
    "# directory = os.fsencode(base_dir)\n",
    "# for file in os.listdir(directory):\n",
    "#     filename = os.fsdecode(file)\n",
    "#     if filename.endswith(img_suffix):\n",
    "#         df = df.append({'image': filename, 'cells': \"\"}, ignore_index = True)\n",
    "# df.to_csv(r'../../20201020134002/dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Index' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bdd614cc3975>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dataset.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Index' object is not callable"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../20201020134002/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Aria1/Area1_Cell_00000001.png', './Aria1/Area1_Cell_00000002.png', './Aria1/Area1_Cell_00000003.png', './Aria1/Area1_Cell_00000004.png', './Aria1/Area1_Cell_00000005.png', './Aria1/Area1_Cell_00000006.png', './Aria1/Area1_Cell_00000007.png', './Aria1/Area1_Cell_00000008.png', './Aria1/Area1_Cell_00000009.png', './Aria1/Area1_Cell_00000010.png', './Aria1/Area1_Cell_00000011.png', './Aria1/Area1_Cell_00000012.png', './Aria1/Area1_Cell_00000013.png', './Aria1/Area1_Cell_00000014.png', './Aria1/Area1_Cell_00000015.png', './Aria1/Area1_Cell_00000016.png', './Aria1/Area1_Cell_00000017.png', './Aria1/Area1_Cell_00000018.png', './Aria1/Area1_Cell_00000019.png', './Aria1/Area1_Cell_00000020.png', './Aria1/Area1_Cell_00000021.png', './Aria1/Area1_Cell_00000022.png', './Aria1/Area1_Cell_00000023.png', './Aria1/Area1_Cell_00000024.png', './Aria1/Area1_Cell_00000025.png', './Aria1/Area1_Cell_00000026.png', './Aria1/Area1_Cell_00000027.png', './Aria1/Area1_Cell_00000028.png', './Aria1/Area1_Cell_00000029.png', './Aria1/Area1_Cell_00000030.png', './Aria1/Area1_Cell_00000031.png', './Aria1/Area1_Cell_00000032.png', './Aria1/Area1_Cell_00000033.png', './Aria1/Area1_Cell_00000034.png', './Aria1/Area1_Cell_00000035.png', './Aria1/Area1_Cell_00000036.png', './Aria1/Area1_Cell_00000037.png', './Aria1/Area1_Cell_00000038.png', './Aria1/Area1_Cell_00000039.png', './Aria1/Area1_Cell_00000040.png', './Aria1/Area1_Cell_00000041.png', './Aria1/Area1_Cell_00000042.png', './Aria1/Area1_Cell_00000043.png', './Aria1/Area1_Cell_00000044.png', './Aria1/Area1_Cell_00000045.png', './Aria1/Area1_Cell_00000046.png', './Aria1/Area1_Cell_00000047.png', './Aria1/Area1_Cell_00000048.png', './Aria1/Area1_Cell_00000049.png', './Aria1/Area1_Cell_00000050.png', './Aria1/Area1_Cell_00000051.png', './Aria1/Area1_Cell_00000052.png', './Aria1/Area1_Cell_00000053.png', './Aria1/Area1_Cell_00000054.png', './Aria1/Area1_Cell_00000055.png', './Aria1/Area1_Cell_00000056.png', './Aria1/Area1_Cell_00000057.png', './Aria1/Area1_Cell_00000058.png', './Aria1/Area1_Cell_00000059.png', './Aria1/Area1_Cell_00000060.png', './Aria1/Area1_Cell_00000061.png', './Aria1/Area1_Cell_00000062.png', './Aria1/Area1_Cell_00000063.png', './Aria1/Area1_Cell_00000064.png', './Aria1/Area1_Cell_00000065.png', './Aria1/Area1_Cell_00000066.png', './Aria1/Area1_Cell_00000067.png', './Aria1/Area1_Cell_00000068.png', './Aria1/Area1_Cell_00000069.png', './Aria1/Area1_Cell_00000070.png', './Aria1/Area1_Cell_00000071.png', './Aria1/Area1_Cell_00000072.png', './Aria1/Area1_Cell_00000073.png', './Aria1/Area1_Cell_00000074.png', './Aria1/Area1_Cell_00000075.png', './Aria1/Area1_Cell_00000076.png', './Aria1/Area1_Cell_00000077.png', './Aria1/Area1_Cell_00000078.png', './Aria1/Area1_Cell_00000079.png', './Aria1/Area1_Cell_00000080.png', './Aria1/Area1_Cell_00000081.png', './Aria1/Area1_Cell_00000082.png', './Aria1/Area1_Cell_00000083.png', './Aria1/Area1_Cell_00000084.png', './Aria1/Area1_Cell_00000085.png', './Aria1/Area1_Cell_00000086.png', './Aria1/Area1_Cell_00000087.png', './Aria1/Area1_Cell_00000088.png', './Aria1/Area1_Cell_00000089.png', './Aria1/Area1_Cell_00000090.png', './Aria1/Area1_Cell_00000091.png', './Aria1/Area1_Cell_00000092.png', './Aria1/Area1_Cell_00000093.png', './Aria1/Area1_Cell_00000094.png', './Aria1/Area1_Cell_00000095.png', './Aria1/Area1_Cell_00000096.png', './Aria1/Area1_Cell_00000097.png', './Aria1/Area1_Cell_00000098.png', './Aria1/Area1_Cell_00000099.png', './Aria1/Area1_Cell_00000100.png', './Aria1/Area1_Cell_00000101.png', './Aria1/Area1_Cell_00000102.png', './Aria1/Area1_Cell_00000103.png', './Aria1/Area1_Cell_00000104.png', './Aria1/Area1_Cell_00000105.png', './Aria1/Area1_Cell_00000106.png', './Aria1/Area1_Cell_00000107.png', './Aria1/Area1_Cell_00000108.png', './Aria1/Area1_Cell_00000109.png', './Aria1/Area1_Cell_00000110.png', './Aria1/Area1_Cell_00000111.png', './Aria1/Area1_Cell_00000112.png', './Aria1/Area1_Cell_00000113.png', './Aria1/Area1_Cell_00000114.png', './Aria1/Area1_Cell_00000115.png', './Aria1/Area1_Cell_00000116.png', './Aria1/Area1_Cell_00000117.png', './Aria1/Area1_Cell_00000118.png', './Aria1/Area1_Cell_00000119.png', './Aria1/Area1_Cell_00000120.png', './Aria1/Area1_Cell_00000121.png', './Aria1/Area1_Cell_00000122.png', './Aria1/Area1_Cell_00000123.png', './Aria1/Area1_Cell_00000124.png', './Aria1/Area1_Cell_00000125.png', './Aria1/Area1_Cell_00000126.png', './Aria1/Area1_Cell_00000127.png', './Aria1/Area1_Cell_00000128.png', './Aria1/Area1_Cell_00000129.png', './Aria1/Area1_Cell_00000130.png', './Aria1/Area1_Cell_00000131.png', './Aria1/Area1_Cell_00000132.png', './Aria1/Area1_Cell_00000133.png', './Aria1/Area1_Cell_00000134.png', './Aria1/Area1_Cell_00000135.png', './Aria1/Area1_Cell_00000136.png', './Aria1/Area1_Cell_00000137.png', './Aria1/Area1_Cell_00000138.png', './Aria1/Area1_Cell_00000139.png', './Aria1/Area1_Cell_00000140.png', './Aria1/Area1_Cell_00000141.png', './Aria1/Area1_Cell_00000142.png', './Aria1/Area1_Cell_00000143.png', './Aria1/Area1_Cell_00000144.png', './Aria1/Area1_Cell_00000145.png', './Aria1/Area1_Cell_00000146.png', './Aria1/Area1_Cell_00000147.png', './Aria1/Area1_Cell_00000148.png', './Aria1/Area1_Cell_00000149.png', './Aria1/Area1_Cell_00000150.png', './Aria1/Area1_Cell_00000151.png', './Aria1/Area1_Cell_00000152.png', './Aria1/Area1_Cell_00000153.png', './Aria1/Area1_Cell_00000154.png', './Aria1/Area1_Cell_00000155.png', './Aria1/Area1_Cell_00000156.png', './Aria1/Area1_Cell_00000157.png', './Aria1/Area1_Cell_00000158.png', './Aria1/Area1_Cell_00000159.png', './Aria1/Area1_Cell_00000160.png', './Aria1/Area1_Cell_00000161.png', './Aria1/Area1_Cell_00000162.png', './Aria1/Area1_Cell_00000163.png', './Aria1/Area1_Cell_00000164.png', './Aria1/Area1_Cell_00000165.png', './Aria1/Area1_Cell_00000166.png', './Aria1/Area1_Cell_00000167.png', './Aria1/Area1_Cell_00000168.png', './Aria1/Area1_Cell_00000169.png', './Aria1/Area1_Cell_00000170.png', './Aria1/Area1_Cell_00000171.png', './Aria1/Area1_Cell_00000172.png', './Aria1/Area1_Cell_00000173.png', './Aria1/Area1_Cell_00000174.png', './Aria1/Area1_Cell_00000175.png', './Aria1/Area1_Cell_00000176.png', './Aria1/Area1_Cell_00000177.png', './Aria1/Area1_Cell_00000178.png', './Aria1/Area1_Cell_00000179.png', './Aria1/Area1_Cell_00000180.png', './Aria1/Area1_Cell_00000181.png', './Aria1/Area1_Cell_00000182.png', './Aria1/Area1_Cell_00000183.png', './Aria1/Area1_Cell_00000184.png', './Aria1/Area1_Cell_00000185.png', './Aria1/Area1_Cell_00000186.png', './Aria1/Area1_Cell_00000187.png', './Aria1/Area1_Cell_00000188.png', './Aria1/Area1_Cell_00000189.png', './Aria1/Area1_Cell_00000190.png', './Aria1/Area1_Cell_00000191.png', './Aria1/Area1_Cell_00000192.png', './Aria1/Area1_Cell_00000193.png', './Aria1/Area1_Cell_00000194.png', './Aria1/Area1_Cell_00000195.png', './Aria1/Area1_Cell_00000196.png', './Aria1/Area1_Cell_00000197.png', './Aria1/Area1_Cell_00000198.png', './Aria1/Area1_Cell_00000199.png', './Aria1/Area1_Cell_00000200.png', './Aria1/Area1_Cell_00000201.png', './Aria1/Area1_Cell_00000202.png', './Aria1/Area1_Cell_00000203.png', './Aria1/Area1_Cell_00000204.png', './Aria1/Area1_Cell_00000205.png', './Aria1/Area1_Cell_00000206.png', './Aria1/Area1_Cell_00000207.png', './Aria1/Area1_Cell_00000208.png', './Aria1/Area1_Cell_00000209.png', './Aria1/Area1_Cell_00000210.png', './Aria1/Area1_Cell_00000211.png', './Aria1/Area1_Cell_00000212.png', './Aria1/Area1_Cell_00000213.png', './Aria1/Area1_Cell_00000214.png', './Aria1/Area1_Cell_00000215.png', './Aria1/Area1_Cell_00000216.png', './Aria1/Area1_Cell_00000217.png', './Aria1/Area1_Cell_00000218.png', './Aria1/Area1_Cell_00000219.png', './Aria1/Area1_Cell_00000220.png', './Aria1/Area1_Cell_00000221.png', './Aria1/Area1_Cell_00000222.png', './Aria1/Area1_Cell_00000223.png', './Aria1/Area1_Cell_00000224.png', './Aria1/Area1_Cell_00000225.png', './Aria1/Area1_Cell_00000226.png', './Aria1/Area1_Cell_00000227.png', './Aria1/Area1_Cell_00000228.png', './Aria1/Area1_Cell_00000229.png', './Aria1/Area1_Cell_00000230.png', './Aria1/Area1_Cell_00000231.png', './Aria1/Area1_Cell_00000232.png', './Aria1/Area1_Cell_00000233.png', './Aria1/Area1_Cell_00000234.png', './Aria1/Area1_Cell_00000235.png', './Aria1/Area1_Cell_00000236.png', './Aria1/Area1_Cell_00000237.png', './Aria1/Area1_Cell_00000238.png', './Aria1/Area1_Cell_00000239.png', './Aria1/Area1_Cell_00000240.png', './Aria1/Area1_Cell_00000241.png', './Aria1/Area1_Cell_00000242.png', './Aria1/Area1_Cell_00000243.png', './Aria1/Area1_Cell_00000244.png', './Aria1/Area1_Cell_00000245.png', './Aria1/Area1_Cell_00000246.png', './Aria1/Area1_Cell_00000247.png', './Aria1/Area1_Cell_00000248.png', './Aria1/Area1_Cell_00000249.png', './Aria1/Area1_Cell_00000250.png', './Aria1/Area1_Cell_00000251.png', './Aria1/Area1_Cell_00000252.png', './Aria1/Area1_Cell_00000253.png', './Aria1/Area1_Cell_00000254.png', './Aria1/Area1_Cell_00000255.png', './Aria1/Area1_Cell_00000256.png', './Aria1/Area1_Cell_00000257.png', './Aria1/Area1_Cell_00000258.png', './Aria1/Area1_Cell_00000259.png', './Aria1/Area1_Cell_00000260.png', './Aria1/Area1_Cell_00000261.png', './Aria1/Area1_Cell_00000262.png', './Aria1/Area1_Cell_00000263.png', './Aria1/Area1_Cell_00000264.png', './Aria1/Area1_Cell_00000265.png', './Aria1/Area1_Cell_00000266.png', './Aria1/Area1_Cell_00000267.png', './Aria1/Area1_Cell_00000268.png', './Aria1/Area1_Cell_00000269.png', './Aria1/Area1_Cell_00000270.png', './Aria1/Area1_Cell_00000271.png', './Aria1/Area1_Cell_00000272.png', './Aria1/Area1_Cell_00000273.png', './Aria1/Area1_Cell_00000274.png', './Aria1/Area1_Cell_00000275.png', './Aria1/Area1_Cell_00000276.png', './Aria1/Area1_Cell_00000277.png', './Aria1/Area1_Cell_00000278.png', './Aria1/Area1_Cell_00000279.png', './Aria1/Area1_Cell_00000280.png', './Aria1/Area1_Cell_00000281.png', './Aria1/Area1_Cell_00000282.png', './Aria1/Area1_Cell_00000283.png', './Aria1/Area1_Cell_00000284.png', './Aria1/Area1_Cell_00000285.png', './Aria1/Area1_Cell_00000286.png', './Aria1/Area1_Cell_00000287.png', './Aria1/Area1_Cell_00000288.png', './Aria1/Area1_Cell_00000289.png', './Aria1/Area1_Cell_00000290.png', './Aria1/Area1_Cell_00000291.png', './Aria1/Area1_Cell_00000292.png', './Aria1/Area1_Cell_00000293.png', './Aria1/Area1_Cell_00000294.png', './Aria1/Area1_Cell_00000295.png', './Aria1/Area1_Cell_00000296.png', './Aria1/Area1_Cell_00000297.png', './Aria1/Area1_Cell_00000298.png', './Aria1/Area1_Cell_00000299.png', './Aria1/Area1_Cell_00000300.png', './Aria1/Area1_Cell_00000301.png', './Aria1/Area1_Cell_00000302.png', './Aria1/Area1_Cell_00000303.png', './Aria1/Area1_Cell_00000304.png', './Aria1/Area1_Cell_00000305.png', './Aria1/Area1_Cell_00000306.png', './Aria1/Area1_Cell_00000307.png', './Aria1/Area1_Cell_00000308.png', './Aria1/Area1_Cell_00000309.png', './Aria1/Area1_Cell_00000310.png', './Aria1/Area1_Cell_00000311.png', './Aria1/Area1_Cell_00000312.png', './Aria1/Area1_Cell_00000313.png', './Aria1/Area1_Cell_00000314.png', './Aria1/Area1_Cell_00000315.png', './Aria1/Area1_Cell_00000316.png', './Aria1/Area1_Cell_00000317.png', './Aria1/Area1_Cell_00000318.png', './Aria1/Area1_Cell_00000319.png', './Aria1/Area1_Cell_00000320.png', './Aria1/Area1_Cell_00000321.png', './Aria1/Area1_Cell_00000322.png', './Aria1/Area1_Cell_00000323.png', './Aria1/Area1_Cell_00000324.png', './Aria1/Area1_Cell_00000325.png', './Aria1/Area1_Cell_00000326.png', './Aria1/Area1_Cell_00000327.png', './Aria1/Area1_Cell_00000328.png', './Aria1/Area1_Cell_00000329.png', './Aria1/Area1_Cell_00000330.png', './Aria1/Area1_Cell_00000331.png', './Aria1/Area1_Cell_00000332.png', './Aria1/Area1_Cell_00000333.png', './Aria1/Area1_Cell_00000334.png', './Aria1/Area1_Cell_00000335.png', './Aria1/Area1_Cell_00000336.png', './Aria1/Area1_Cell_00000337.png', './Aria1/Area1_Cell_00000338.png', './Aria1/Area1_Cell_00000339.png', './Aria1/Area1_Cell_00000340.png', './Aria1/Area1_Cell_00000341.png', './Aria1/Area1_Cell_00000342.png', './Aria1/Area1_Cell_00000343.png', './Aria1/Area1_Cell_00000344.png', './Aria1/Area1_Cell_00000345.png', './Aria1/Area1_Cell_00000346.png', './Aria1/Area1_Cell_00000347.png', './Aria1/Area1_Cell_00000348.png', './Aria1/Area1_Cell_00000349.png', './Aria1/Area1_Cell_00000350.png', './Aria1/Area1_Cell_00000351.png', './Aria1/Area1_Cell_00000352.png', './Aria1/Area1_Cell_00000353.png', './Aria1/Area1_Cell_00000354.png', './Aria1/Area1_Cell_00000355.png', './Aria1/Area1_Cell_00000356.png', './Aria1/Area1_Cell_00000357.png', './Aria1/Area1_Cell_00000358.png', './Aria1/Area1_Cell_00000359.png', './Aria1/Area1_Cell_00000360.png', './Aria1/Area1_Cell_00000361.png', './Aria1/Area1_Cell_00000362.png', './Aria1/Area1_Cell_00000363.png', './Aria1/Area1_Cell_00000364.png', './Aria1/Area1_Cell_00000365.png', './Aria1/Area1_Cell_00000366.png', './Aria1/Area1_Cell_00000367.png', './Aria1/Area1_Cell_00000368.png', './Aria1/Area1_Cell_00000369.png', './Aria1/Area1_Cell_00000370.png', './Aria1/Area1_Cell_00000371.png', './Aria1/Area1_Cell_00000372.png', './Aria1/Area1_Cell_00000373.png', './Aria1/Area1_Cell_00000374.png', './Aria1/Area1_Cell_00000375.png', './Aria1/Area1_Cell_00000376.png', './Aria1/Area1_Cell_00000377.png', './Aria1/Area1_Cell_00000378.png', './Aria1/Area1_Cell_00000379.png', './Aria1/Area1_Cell_00000380.png', './Aria1/Area1_Cell_00000381.png', './Aria1/Area1_Cell_00000382.png', './Aria1/Area1_Cell_00000383.png', './Aria1/Area1_Cell_00000384.png', './Aria1/Area1_Cell_00000385.png', './Aria1/Area1_Cell_00000386.png', './Aria1/Area1_Cell_00000387.png', './Aria1/Area1_Cell_00000388.png', './Aria1/Area1_Cell_00000389.png', './Aria1/Area1_Cell_00000390.png', './Aria1/Area1_Cell_00000391.png', './Aria1/Area1_Cell_00000392.png', './Aria1/Area1_Cell_00000393.png', './Aria1/Area1_Cell_00000394.png', './Aria1/Area1_Cell_00000395.png', './Aria1/Area1_Cell_00000396.png', './Aria1/Area1_Cell_00000397.png', './Aria1/Area1_Cell_00000398.png', './Aria1/Area1_Cell_00000399.png', './Aria1/Area1_Cell_00000400.png']\n"
     ]
    }
   ],
   "source": [
    "# img = data[data.columns[0]]\n",
    "# for i in range (0, 400):\n",
    "#     print(i)\n",
    "\n",
    "# imagepaths, cells = list(), list()\n",
    "# img_list = data[data.columns[0]]\n",
    "# cell_list = data[data.columns[1]]\n",
    "# for idx in range (0, 400):\n",
    "#     imagepaths.append(\"./Aria1/\" + img_list[idx])\n",
    "#     cells.append(int(cell_list[idx]))\n",
    "# print(imagepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image parameters\n",
    "Channels = 3\n",
    "\n",
    "base_dir = \"../../20201020134002/\"\n",
    "\n",
    "def read_images(dataset_dir, batch_size):\n",
    "    imagepaths, cells = list(), list()\n",
    "    data = pd.read_csv(dataset_dir)\n",
    "    img_list = data[data.columns[0]]\n",
    "    cell_list = data[data.columns[1]]\n",
    "    for idx in range (0, 400):\n",
    "        imagepaths.append(base_dir + \"./Aria1/\" + img_list[idx])\n",
    "        cells.append(str(cell_list[idx]))\n",
    "    \n",
    "    imagepaths = tf.convert_to_tensor(imagepaths, dtype = tf.string)\n",
    "    cells = tf.convert_to_tensor(cells, dtype = tf.string)\n",
    "    image, cell = tf.data.Dataset.from_tensor_slices([imagepaths, cells])\n",
    "    \n",
    "    image = tf.io.read_file(image)\n",
    "    image = tf.image.decode_jpeg(image, channels = Channels)\n",
    "    \n",
    "    X, Y = tf.train.batch([image, cell], batch_size = batch_size, capacity = batch_size * 8, num_threads = 4)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-45-6e69b8e88df8>:15: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\juntingma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:371: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\juntingma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:317: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input pipelines based on Queues are not supported when eager execution is enabled. Please use tf.data to ingest data into your model instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-95e7b4a466ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Build the data input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-45-6e69b8e88df8>\u001b[0m in \u001b[0;36mread_images\u001b[1;34m(dataset_dir, batch_size)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mimagepaths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagepaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mcells\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcells\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_input_producer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimagepaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcells\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py\u001b[0m in \u001b[0;36mslice_input_producer\u001b[1;34m(tensor_list, num_epochs, shuffle, seed, capacity, shared_name, name)\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[1;31m# TODO(josh11b): Add an assertion that the first dimension of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;31m# everything in TensorList matches. Maybe just check the inferred shapes?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m     queue = range_input_producer(range_size, num_epochs=num_epochs,\n\u001b[0m\u001b[0;32m    372\u001b[0m                                  \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapacity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcapacity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m                                  shared_name=shared_name)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py\u001b[0m in \u001b[0;36mrange_input_producer\u001b[1;34m(limit, num_epochs, shuffle, seed, capacity, shared_name, name)\u001b[0m\n\u001b[0;32m    315\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"input_producer\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[0mrange_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m     return input_producer(\n\u001b[0m\u001b[0;32m    318\u001b[0m         \u001b[0mrange_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapacity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         shared_name, \"fraction_of_%d_full\" % capacity, name)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py\u001b[0m in \u001b[0;36minput_producer\u001b[1;34m(input_tensor, element_shape, num_epochs, shuffle, seed, capacity, shared_name, summary_name, name, cancel_op)\u001b[0m\n\u001b[0;32m    173\u001b[0m   \"\"\"\n\u001b[0;32m    174\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m     raise RuntimeError(\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[1;34m\"Input pipelines based on Queues are not supported when eager execution\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;34m\" is enabled. Please use tf.data to ingest data into your model\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input pipelines based on Queues are not supported when eager execution is enabled. Please use tf.data to ingest data into your model instead."
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# THIS IS A CLASSIC CNN (see examples, section 3)\n",
    "# -----------------------------------------------\n",
    "# Note that a few elements have changed (usage of queues).\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 10000\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "DATASET_PATH = base_dir + \"dataset.csv\"\n",
    "\n",
    "# Build the data input\n",
    "X, Y = read_images(DATASET_PATH, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
