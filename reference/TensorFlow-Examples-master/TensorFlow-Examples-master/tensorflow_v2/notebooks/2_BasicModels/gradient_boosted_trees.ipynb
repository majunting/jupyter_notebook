{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Decision Tree (GBDT)\n",
    "Implement a Gradient Boosted Decision Tree (GBDT) with TensorFlow. This example is using the Boston Housing Value dataset as training samples. The example supports both Classification (2 classes: value > $23000 or not) and Regression (raw home value as target).\n",
    "\n",
    "- Author: Aymeric Damien\n",
    "- Project: https://github.com/aymericdamien/TensorFlow-Examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston Housing Dataset\n",
    "\n",
    "**Link:** https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\n",
    "\n",
    "**Description:**\n",
    "\n",
    "The dataset contains information collected by the U.S Census Service concerning housing in the area of Boston Mass. It was obtained from the StatLib archive (http://lib.stat.cmu.edu/datasets/boston), and has been used extensively throughout the literature to benchmark algorithms. However, these comparisons were primarily done outside of Delve and are thus somewhat suspect. The dataset is small in size with only 506 cases.\n",
    "\n",
    "The data was originally published by Harrison, D. and Rubinfeld, D.L. `Hedonic prices and the demand for clean air', J. Environ. Economics & Management, vol.5, 81-102, 1978.`\n",
    "\n",
    "*For the full features list, please see the link above*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Ignore all GPUs (current TF GBDT does not support GPU).\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters.\n",
    "num_classes = 2 # Total classes: greater or equal to $23,000, or not (See notes below).\n",
    "num_features = 13 # data features size.\n",
    "\n",
    "# Training parameters.\n",
    "max_steps = 2000\n",
    "batch_size = 256\n",
    "learning_rate = 1.0\n",
    "l1_regul = 0.0\n",
    "l2_regul = 0.1\n",
    "\n",
    "# GBDT parameters.\n",
    "num_batches_per_layer = 1000\n",
    "num_trees = 10\n",
    "max_depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Prepare Boston Housing Dataset.\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "# For classification purpose, we build 2 classes: price greater or lower than $23,000\n",
    "def to_binary_class(y):\n",
    "    for i, label in enumerate(y):\n",
    "        if label >= 23.0:\n",
    "            y[i] = 1\n",
    "        else:\n",
    "            y[i] = 0\n",
    "    return y\n",
    "\n",
    "y_train_binary = to_binary_class(copy.deepcopy(y_train))\n",
    "y_test_binary = to_binary_class(copy.deepcopy(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\juntingma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:63: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the input function.\n",
    "train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_train}, y=y_train_binary,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "test_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_test}, y=y_test_binary,\n",
    "    batch_size=batch_size, num_epochs=1, shuffle=False)\n",
    "test_train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_train}, y=y_train_binary,\n",
    "    batch_size=batch_size, num_epochs=1, shuffle=False)\n",
    "# GBDT Models from TF Estimator requires 'feature_column' data format.\n",
    "feature_columns = [tf.feature_column.numeric_column(key='x', shape=(num_features,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\JUNTIN~1\\AppData\\Local\\Temp\\tmpq8kei5ig\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\JUNTIN~1\\\\AppData\\\\Local\\\\Temp\\\\tmpq8kei5ig', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "gbdt_classifier = tf.estimator.BoostedTreesClassifier(\n",
    "    n_batches_per_layer=num_batches_per_layer,\n",
    "    feature_columns=feature_columns, \n",
    "    n_classes=num_classes,\n",
    "    learning_rate=learning_rate, \n",
    "    n_trees=num_trees,\n",
    "    max_depth=max_depth,\n",
    "    l1_regularization=l1_regul, \n",
    "    l2_regularization=l2_regul\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\juntingma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From C:\\Users\\juntingma\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:60: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\juntingma\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Users\\juntingma\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:906: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\JUNTIN~1\\AppData\\Local\\Temp\\tmpq8kei5ig\\model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.225 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.099 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.099 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.091 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.084 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.097 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.088 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.088 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.094 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.7596\n",
      "INFO:tensorflow:loss = 0.6931473, step = 100 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 914.976\n",
      "INFO:tensorflow:loss = 0.6931473, step = 200 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 912.615\n",
      "INFO:tensorflow:loss = 0.6931473, step = 300 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 983.669\n",
      "INFO:tensorflow:loss = 0.6931473, step = 400 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 974.119\n",
      "INFO:tensorflow:loss = 0.6931473, step = 500 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 1054.72\n",
      "INFO:tensorflow:loss = 0.6931473, step = 600 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 877.376\n",
      "INFO:tensorflow:loss = 0.6931473, step = 700 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 990.809\n",
      "INFO:tensorflow:loss = 0.6931473, step = 800 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1010.33\n",
      "INFO:tensorflow:loss = 0.6931473, step = 900 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 1000.19\n",
      "INFO:tensorflow:loss = 0.4763421, step = 1000 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 904.025\n",
      "INFO:tensorflow:loss = 0.4864641, step = 1100 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 928.617\n",
      "INFO:tensorflow:loss = 0.44230008, step = 1200 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 869.713\n",
      "INFO:tensorflow:loss = 0.47056565, step = 1300 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 903.306\n",
      "INFO:tensorflow:loss = 0.4414911, step = 1400 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 934.1\n",
      "INFO:tensorflow:loss = 0.4564277, step = 1500 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 863.756\n",
      "INFO:tensorflow:loss = 0.46176738, step = 1600 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 899.893\n",
      "INFO:tensorflow:loss = 0.47161072, step = 1700 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 929.953\n",
      "INFO:tensorflow:loss = 0.4516183, step = 1800 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 929.601\n",
      "INFO:tensorflow:loss = 0.4457296, step = 1900 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.343\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\JUNTIN~1\\AppData\\Local\\Temp\\tmpq8kei5ig\\model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\n",
      "INFO:tensorflow:Loss for final step: 0.4735074.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.boosted_trees.BoostedTreesClassifier at 0x16028b55940>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_classifier.train(train_input_fn, max_steps=max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\juntingma\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\head.py:637: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-10-15T13:58:07Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\JUNTIN~1\\AppData\\Local\\Temp\\tmpq8kei5ig\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.39123s\n",
      "INFO:tensorflow:Finished evaluation at 2020-10-15-13:58:07\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.87376237, accuracy_baseline = 0.63118815, auc = 0.92280567, auc_precision_recall = 0.9104949, average_loss = 0.38155547, global_step = 2000, label/mean = 0.36881188, loss = 0.38539094, precision = 0.8888889, prediction/mean = 0.3786114, recall = 0.7516779\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: C:\\Users\\JUNTIN~1\\AppData\\Local\\Temp\\tmpq8kei5ig\\model.ckpt-2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.87376237,\n",
       " 'accuracy_baseline': 0.63118815,\n",
       " 'auc': 0.92280567,\n",
       " 'auc_precision_recall': 0.9104949,\n",
       " 'average_loss': 0.38155547,\n",
       " 'label/mean': 0.36881188,\n",
       " 'loss': 0.38539094,\n",
       " 'precision': 0.8888889,\n",
       " 'prediction/mean': 0.3786114,\n",
       " 'recall': 0.7516779,\n",
       " 'global_step': 2000}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_classifier.evaluate(test_train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-10-15T13:58:09Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\JUNTIN~1\\AppData\\Local\\Temp\\tmpq8kei5ig\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.38030s\n",
      "INFO:tensorflow:Finished evaluation at 2020-10-15-13:58:09\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.78431374, accuracy_baseline = 0.5588235, auc = 0.8458089, auc_precision_recall = 0.86285317, average_loss = 0.49375325, global_step = 2000, label/mean = 0.44117647, loss = 0.49375325, precision = 0.87096775, prediction/mean = 0.37429693, recall = 0.6\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: C:\\Users\\JUNTIN~1\\AppData\\Local\\Temp\\tmpq8kei5ig\\model.ckpt-2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.78431374,\n",
       " 'accuracy_baseline': 0.5588235,\n",
       " 'auc': 0.8458089,\n",
       " 'auc_precision_recall': 0.86285317,\n",
       " 'average_loss': 0.49375325,\n",
       " 'label/mean': 0.44117647,\n",
       " 'loss': 0.49375325,\n",
       " 'precision': 0.87096775,\n",
       " 'prediction/mean': 0.37429693,\n",
       " 'recall': 0.6,\n",
       " 'global_step': 2000}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_classifier.evaluate(test_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the input function.\n",
    "train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_train}, y=y_train,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "test_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_test}, y=y_test,\n",
    "    batch_size=batch_size, num_epochs=1, shuffle=False)\n",
    "# GBDT Models from TF Estimator requires 'feature_column' data format.\n",
    "feature_columns = [tf.feature_column.numeric_column(key='x', shape=(num_features,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\JUNTIN~1\\AppData\\Local\\Temp\\tmpihbojfxq\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\JUNTIN~1\\\\AppData\\\\Local\\\\Temp\\\\tmpihbojfxq', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "gbdt_regressor = tf.estimator.BoostedTreesRegressor(\n",
    "    n_batches_per_layer=num_batches_per_layer,\n",
    "    feature_columns=feature_columns, \n",
    "    learning_rate=learning_rate, \n",
    "    n_trees=num_trees,\n",
    "    max_depth=max_depth,\n",
    "    l1_regularization=l1_regul, \n",
    "    l2_regularization=l2_regul\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\JUNTIN~1\\AppData\\Local\\Temp\\tmpihbojfxq\\model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 594.67346, step = 0\n",
      "INFO:tensorflow:loss = 584.89355, step = 0 (0.196 sec)\n",
      "INFO:tensorflow:loss = 578.9044, step = 0 (0.092 sec)\n",
      "INFO:tensorflow:loss = 564.72485, step = 0 (0.101 sec)\n",
      "INFO:tensorflow:loss = 564.03, step = 0 (0.104 sec)\n",
      "INFO:tensorflow:loss = 572.6944, step = 0 (0.111 sec)\n",
      "INFO:tensorflow:loss = 629.07556, step = 0 (0.115 sec)\n",
      "INFO:tensorflow:loss = 582.0185, step = 0 (0.123 sec)\n",
      "INFO:tensorflow:loss = 605.8288, step = 0 (0.119 sec)\n",
      "INFO:tensorflow:loss = 615.21387, step = 0 (0.117 sec)\n",
      "INFO:tensorflow:loss = 607.41595, step = 0 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.7459\n",
      "INFO:tensorflow:loss = 609.9785, step = 100 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 779.044\n",
      "INFO:tensorflow:loss = 554.57574, step = 200 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 732.581\n",
      "INFO:tensorflow:loss = 537.22797, step = 300 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 707.842\n",
      "INFO:tensorflow:loss = 587.3819, step = 400 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 745.032\n",
      "INFO:tensorflow:loss = 587.9943, step = 500 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 732.653\n",
      "INFO:tensorflow:loss = 621.8413, step = 600 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.038\n",
      "INFO:tensorflow:loss = 518.0762, step = 700 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 748.776\n",
      "INFO:tensorflow:loss = 496.29736, step = 800 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 732.276\n",
      "INFO:tensorflow:loss = 579.7262, step = 900 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 748.719\n",
      "INFO:tensorflow:loss = 73.15656, step = 1000 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 721.866\n",
      "INFO:tensorflow:loss = 51.916145, step = 1100 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 668.896\n",
      "INFO:tensorflow:loss = 45.570087, step = 1200 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 730.391\n",
      "INFO:tensorflow:loss = 51.586975, step = 1300 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 720.018\n",
      "INFO:tensorflow:loss = 49.434578, step = 1400 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 674.573\n",
      "INFO:tensorflow:loss = 56.444553, step = 1500 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 771.321\n",
      "INFO:tensorflow:loss = 56.54261, step = 1600 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.508\n",
      "INFO:tensorflow:loss = 55.38705, step = 1700 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 745.898\n",
      "INFO:tensorflow:loss = 63.20424, step = 1800 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.678\n",
      "INFO:tensorflow:loss = 55.087524, step = 1900 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 718.656\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\JUNTIN~1\\AppData\\Local\\Temp\\tmpihbojfxq\\model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\n",
      "INFO:tensorflow:Loss for final step: 57.12911.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.boosted_trees.BoostedTreesRegressor at 0x16031f9b790>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_regressor.train(train_input_fn, max_steps=max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-10-15T13:58:16Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\JUNTIN~1\\AppData\\Local\\Temp\\tmpihbojfxq\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.20830s\n",
      "INFO:tensorflow:Finished evaluation at 2020-10-15-13:58:17\n",
      "INFO:tensorflow:Saving dict for global step 2000: average_loss = 29.68814, global_step = 2000, label/mean = 23.078432, loss = 29.68814, prediction/mean = 22.495617\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: C:\\Users\\JUNTIN~1\\AppData\\Local\\Temp\\tmpihbojfxq\\model.ckpt-2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'average_loss': 29.68814,\n",
       " 'label/mean': 23.078432,\n",
       " 'loss': 29.68814,\n",
       " 'prediction/mean': 22.495617,\n",
       " 'global_step': 2000}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_regressor.evaluate(test_input_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
